{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI6 - Assignment 1 - Linear Regression & Gradient Descent\n",
    "\n",
    "Lets implement the gradient descent algorithm for a simple linear regression problem. \n",
    "\n",
    "It is assumed that you know what Linear Regression is. For a refresher, head here [Simple Linear Regression](https://onlinecourses.science.psu.edu/stat501/node/251/)\n",
    "\n",
    "For understanding Gradient Descent, watch the lectures titled **C1W2L04, C1W2L09, C1W2L10** in this Youtube playlist.  \n",
    "[Neural Networks](https://www.youtube.com/watch?v=CS4cs9xVecg&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0)  \n",
    "\n",
    "Follow this code tutorial. [Linear Regression with Gradient Descent](https://towardsdatascience.com/linear-regression-using-gradient-descent-in-10-lines-of-code-642f995339c0)  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**  \n",
    "This is a random dataset with just one input variable X and the output y.  \n",
    "Lets import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('data/linear_reg_data.csv', delimiter=',')\n",
    "X, y = data[:, 0], data[:, 1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X, y)\n",
    "plt.title('Data with a linear relationship')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Use these formula for MSE & Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MSE](images/mse.gif)\n",
    "![Gradient Descent Formula](images/gradient_descent_eqn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(X, y, m_current=0, b_current=0, epochs=1000, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X : array of predictor features\n",
    "    y : array of outcome values\n",
    "    m_current, b_current : current values of co-efficients\n",
    "    epochs : number of iterations\n",
    "    learn_rate : learning rate\n",
    "\n",
    "    Returns\n",
    "    m_current, b_current : values of co-efficients after gradient descent steps\n",
    "    \"\"\"\n",
    "    N = float(len(y))\n",
    "    for i in range(epochs):\n",
    "        # Enter your code\n",
    "        # --------------\n",
    "        \n",
    "        \n",
    "        # End your code\n",
    "        \n",
    "    return m_current, b_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets run our code for 100 epochs, i.e. 100 gradient descent steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_current, b_current = linear_regression(X, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets plot and see how our model performs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for visualizing our model\n",
    "def plot_linear_reg(X, y, co_efficients):\n",
    "    X_min, X_max = X.min(), X.max()    \n",
    "    counter = len(co_efficients)\n",
    "    for m_current, b_current in co_efficients:\n",
    "        counter -= 1\n",
    "        color = [1 - 0.92 ** counter for _ in range(3)]\n",
    "        plt.plot([X_min, X_max],[X_min * m_current + b_current, X_max * m_current + b_current], color = color)\n",
    "    plt.scatter(X, y, zorder = 3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just creating a list to store co-efficient values\n",
    "co_efficients = [(m_current, b_current)]\n",
    "\n",
    "plot_linear_reg(X, y, co_efficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thats looks bad, lets run it for 1000 iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_current, b_current = linear_regression(X, y, epochs=1000)\n",
    "\n",
    "co_efficients = [(m_current, b_current)]\n",
    "\n",
    "plot_linear_reg(X, y, co_efficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our line is moving closer to our data points, so our model is improving.  \n",
    "It would be cool to see it in action!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* Lets start with 0 co-efficients and run gradient descent steps for 1500 times.\n",
    "* And visualize our model at every 100th step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_current, b_current = 0, 0\n",
    "co_efficients = [(m_current, b_current)]\n",
    "\n",
    "for i in range(1, 1500, 100):\n",
    "    m_current, b_current = linear_regression(X, y, m_current=m_current, b_current=b_current, epochs=100)\n",
    "    co_efficients.append((m_current, b_current))\n",
    "\n",
    "plot_linear_reg(X, y, co_efficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that our model starts with the bottom most grey line and over time it gets better. Pretty cool, huh!  \n",
    "\n",
    "Our final model is represented as a solid black line.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with epochs and learning rate to see how slow or fast the model learns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Playgroud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit \n",
    "\n",
    "Calculate **Cost Function** in your model and use convergence to stop the gradient descent algorithm.  \n",
    "\n",
    "Hint : We used epochs to set the number of iterations of gradient descent steps... Along with that, use the cost value to break the gradient descent algorithm after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
